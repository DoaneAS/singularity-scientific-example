# Primer: What are containers, and how can they be used to increase research integrity and reproducibility?

## Cameron J. Prybol<sup>1</sup>, Euan A. Ashley<sup>1, 2, 3</sup>

### <sup>1</sup> Department of Genetics, Stanford University, Stanford, CA, 94305, USA., <sup>2</sup>Department of Medicine, Stanford University, Stanford, CA, 94305, USA., <sup>3</sup>Stanford Center for Inherited Cardiovascular Disease, Stanford University, Stanford, CA, 94305, USA.

## Abstract

As computational biologists continue to push the performance boundaries of high-performance computing (HPC) clusters with ever-growing datasets and algorithmic complexity, the process of configuring and maintaining these computing environments also grows in complexity. Without a sufficiently similar computing environment (i.e. same software, version numbers, operating system, shell environment) it can be prohibitively difficult to replicate results, even when given the same input code and datasets. As system administrators make upgrades to computing infrastructure to improve reliability, patch security issues, and enhance user experience, researchers may not be able to replicate their own results only months after the completion of a project due to system changes. Containers are isolated, fully-functional computing environments that abstract entire operating systems, along with all configurations and software necessary to perform analyses, into single files. Containers can be built on local and personal computers, enabling researchers to have full admin permissions, and thus additional freedom and flexibility to configure a computing environment that best suits their needs. These contained computing environments can then be distributed to clusters, collaborators, and most importantly, journals and archiving services upon the publication of manuscripts. All in all, containers enable researchers to spend more time focusing on research and less time troubleshooting system-specific configuration issues, while at the same time promoting transparancy and integrity in research by lowering the barrier for others to replicate and review results.

## Introduction

Reproducibility is at the core of scientific philosophy, yet one does not need to look far to find papers published today that woefully incomplete descriptions of computational methods and analyses. Even in cases where the software used, commands executed, and versions required are meticulously curated for the final publication, configuring a computing enviroment that precisely matches the one used in the publication can turn into a research project in and of itself, with hours and days lost searching the web with unintelligible error messages. Given that computers, both by definition and by design, and meant to recieve instructions and execute those instructions to yield a deterministic result, it may seem counter-intuitive that many wet-lab bench analyses are easier to replicate than computational ones. One need look no further than the constrast in how young scientists percieve learning to perform a polymerase-chain reaction (PCR) amplification, a technique developed in the mid-1980's, to how young scientists percieve the task of learning to use Unix-based operating systems, which have existed since the mid- to late-1960's. The former has many user-friendly and robust tools available for assay design, such as Primer3Plus [cite] and NCBI's Primer-BLAST [cite], as well as easy-to-use interfaces for configuring and running thermal cyclers. The latter is one of the more frightening learning-curves that new scientists face as they learn to work with datasets that are too heterogenous or too large for ExcelÂ®.

Educational efforts like Software Carpentry and the Mozilla Science Lab have evangelized best-practices used by software developers in order to improve computational literacy and reproducibility across the sciences. Open-source platforms like the web-facing Galaxy project, command-line interface (CLI)-facing bcbio-nextgen, and commercial services like DNAnexus enable users to run analyses using customizable scripts and rigorously validated pipelines and software. However, these services are focused on specific use-cases within the domain of computional biology, which can make them cumbersome for novel analyses and limits their adoption across disciplines. As many universities and research institutions have invested in on-site HPC clusters, and researchers across all domains have experience writing analyses using command line applications and tools that run on linux- and unix-based operating systems, an ideal solution for reproducable research would be one that allowed researchers to use existing infrastructure and skill-sets, and does not require any modificications to their existing code.

Many researchers are already familiar with version-control software like git, mercurial, and svn that allow users to effeciently backup, collaborate on, and distribute the code they use in their projects and analyses. Many journals and funding agencies require data to be made available on archiving services like the Gene Expression Omnibus and European Nucleotide Archive. By combining these existing services with containers, or mobile, host-isolated, operating systems in a file, end-users who wish to reproduce results need only an internet connection, sufficient resources to store and process the data, and to have the container software installed. This dramatically lowers the energy and skill required for others to review and learn from your work, while also encouraging transparancy and quality of research and increasing the rate of knowledge transfer. Additionally, it reduces the burden on the research staff who maintain these HPC clusters by allowing them to focus on maintaining only the software required to run the containers and maximizing the performance of the cluster, rather than also having to maintain the diverse software requirements across research groups.

In this publication, we introduce Singularity, a container platform specifically designed for the shared computing environments of HPC clusters at large research institutions. For readers who are familiar with the various container implementations currently available, see the Discussion section for details why we specifically chose Singularity for the purposes of this analysis, as well as details about other options well suited for researchers.

# Methods

We sought to meet two goals with this analysis. The first goal was to implement an example analysis pipeline, from data acquisition through to the production of figures, that executes entirely within the environment of a container. The second goal was to evaluate the resource overhead of running analysis within containers. Given how large the resource requirements already are for analyzing large datasets like GTEx, ExAC, UK10K, and others, it's critical that isolating computing environments with containers not incur significant resource overhead.

![figure 1: workflow of analysis](path/to/file)

To compare the overhead of running analyses using isolated environments within Singularity containers to running analyses using software installed directly onto the host, we performed several iterations of two benchmarks. The first benchmark quantifies transcript abundances of >68 million 2x75bp reads (Human polyA+ total RNA, GM12878 cell line) from round 1 of the RNA-seq Genome Annotation Assessment Project (http://www.gencodegenes.org/rgasp/data.html) using kallisto [cite]. The second benchmark maps 100 million 2x75bp reads to GRCh38 (ensembl release 85) using bwa [cite]. Each iteration of simulation ran the host and container tests in parallel in an attempt to capture the effects of system load as similarly as we could. Iterations were performed in serial over several days. To test a java-based application, which may have different running behavior inside of containers compared to compiled C code, we also tested the non-commercial RTG-core suite of tools by mapping the Ashkenazi trio provided by GIAB to GRCh38, and then calling variants using a pedigree-aware variant calling and haplotype-phasing.

For full details including operating systems, cpu architecture, and version numbers of all software used, see the supplementary material. The instructions for how to acquire the code and Singularity container are available at https://github.com/cjprybol/singularity-manuscript. The datasets used for this analyses are all open access, and are automatically downloaded as part of the analysis.

# Results



# Disussion

Users can install software into containers and configure them in the same way they would any other unix- or linux-based operating system. Containers can execute existing source code, often with no modifications required, which allows researchers to utilize it's added benefits of enviroment isolation and reproducability with minimal disturbance to their normal workflows. The authors would like to explicity draw attention to the fact that, unlike how containers are being used in enterprise settings, whereby each application of piece of software is distributed seperately, we are intentionally designing project-complete containers that house all of the necessary software to perform the complete analysis of a project.

We performed this analysis using Singularity containers. Singularity is not the only container platform available to researchers. However, Singularity has many advantages over other container platforms, specifically containers designed for commercial and enterprise "cloud" computing services such as Docker and rkt. Singularity, developed at the the Lawrence-Berkeley National Laboratory, implements it's own container specification and runtime engine, but functionality is being added to enable researchers to convert Docker containers into Singularity containers.

Docker is a very popular container platform that has strong enterprise backing, a well developed community, and cross-platform support. There have been several projects that have invested in Docker and it's utility to the research community. Bioboxes (cite Bioboxes: standardised containers for interchangeable bioinformatics software), BioShaDock (cite BioShaDock: a community driven bioinformatics shared Docker-based tools registry), and Biodocker (cite website) are registries for Docker containers where users can share and download ready-to-use containers. These services primarily host containers that package individual software libraries seperately, rather than including all of the software necessarily to reproduce a publication in a single container.

Unfortunately, because Docker's target audience has been commercial and enterprise usage by experienced developers, it has incredibly extensive functionality that can be overwhelming for many users, and most importantly, Docker-daemon always runs as root. This means that if university IT departments were to make Docker available to researchers on shared HPC clusters, any and all users would have full access to the entire filesystem, which puts the integrity of files owned by the operating system and files owned by others at risk. To avoid these issues, several container specifications have been developed to allow researchers to access the convenience and reliability of contained computing enviroments while ensuring that processes run by the container retain the user- and group-level permissions of the researcher who is running the commands. Charliecloud, developed at the Los Alamos National Laboratory, is designed to run Docker containers in an unpriviledged state, giving researchers full access to entire Docker ecosystem. Shifter, developed by the National Energy Research Scientific Computing Center, provides a full container specification and runtime engine, similar to Singularity. Additionally, containers can be read by multiple processes at once, making them fully parallelizable.

Additional benefits to utilizing containers includes the ability to distribute required software across multiple containers. For example, legacy software that requires outdated operating systems and dependencies can be installed into their own container(s), and modern software that have conflicting dependencies can be installed to seperate containers to eliminate library conflicts. All of these containers can be utilized on the same clusters, improving researcher and system administrator productivity by reducing the effort required to maintain environments.

**Availability**: Singularity is available at http://singularity.lbl.gov/. Examples of how to create and utilize containers for research projects are available at https://github.com/cjprybol/reproducibility-via-singularity. The repository associated with the manuscript is available at https://github.com/cjprybol/singularity-manuscript

**Contact**: euan@stanford.edu, gmkurtzer@lbl.gov
